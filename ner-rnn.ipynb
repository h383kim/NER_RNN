{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f2d133",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:01.064589Z",
     "iopub.status.busy": "2024-11-11T22:50:01.064154Z",
     "iopub.status.idle": "2024-11-11T22:50:02.459967Z",
     "shell.execute_reply": "2024-11-11T22:50:02.458957Z"
    },
    "papermill": {
     "duration": 1.412445,
     "end_time": "2024-11-11T22:50:02.462676",
     "exception": false,
     "start_time": "2024-11-11T22:50:01.050231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/ner-dataset/NER_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a83b2a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:02.489041Z",
     "iopub.status.busy": "2024-11-11T22:50:02.488656Z",
     "iopub.status.idle": "2024-11-11T22:50:02.513321Z",
     "shell.execute_reply": "2024-11-11T22:50:02.512173Z"
    },
    "papermill": {
     "duration": 0.040101,
     "end_time": "2024-11-11T22:50:02.515649",
     "exception": false,
     "start_time": "2024-11-11T22:50:02.475548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>['Thousands', 'of', 'demonstrators', 'have', '...</td>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>['Iranian', 'officials', 'say', 'they', 'expec...</td>\n",
       "      <td>['JJ', 'NNS', 'VBP', 'PRP', 'VBP', 'TO', 'VB',...</td>\n",
       "      <td>['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>['Helicopter', 'gunships', 'Saturday', 'pounde...</td>\n",
       "      <td>['NN', 'NNS', 'NNP', 'VBD', 'JJ', 'NNS', 'IN',...</td>\n",
       "      <td>['O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>['They', 'left', 'after', 'a', 'tense', 'hour-...</td>\n",
       "      <td>['PRP', 'VBD', 'IN', 'DT', 'NN', 'JJ', 'NN', '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>['U.N.', 'relief', 'coordinator', 'Jan', 'Egel...</td>\n",
       "      <td>['NNP', 'NN', 'NN', 'NNP', 'NNP', 'VBD', 'NNP'...</td>\n",
       "      <td>['B-geo', 'O', 'O', 'B-per', 'I-per', 'O', 'B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>Sentence: 9995</td>\n",
       "      <td>['Opposition', 'leader', 'Mir', 'Hossein', 'Mo...</td>\n",
       "      <td>['NNP', 'NN', 'NNP', 'NNP', 'NNP', 'VBZ', 'VBN...</td>\n",
       "      <td>['O', 'O', 'O', 'B-per', 'I-per', 'O', 'O', 'O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>Sentence: 9996</td>\n",
       "      <td>['On', 'Thursday', ',', 'Iranian', 'state', 'm...</td>\n",
       "      <td>['IN', 'NNP', ',', 'JJ', 'NN', 'NNS', 'VBN', '...</td>\n",
       "      <td>['O', 'B-tim', 'O', 'B-gpe', 'O', 'O', 'O', 'O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>Sentence: 9997</td>\n",
       "      <td>['Following', 'Iran', \"'s\", 'disputed', 'June'...</td>\n",
       "      <td>['VBG', 'NNP', 'POS', 'JJ', 'NNP', 'CD', 'NNS'...</td>\n",
       "      <td>['O', 'B-geo', 'O', 'O', 'B-tim', 'I-tim', 'O'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>Sentence: 9998</td>\n",
       "      <td>['Since', 'then', ',', 'authorities', 'have', ...</td>\n",
       "      <td>['IN', 'RB', ',', 'NNS', 'VBP', 'VBN', 'JJ', '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>Sentence: 9999</td>\n",
       "      <td>['The', 'United', 'Nations', 'is', 'praising',...</td>\n",
       "      <td>['DT', 'NNP', 'NNP', 'VBZ', 'VBG', 'DT', 'NN',...</td>\n",
       "      <td>['O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sentence_ID                                               Word  \\\n",
       "0          Sentence: 1  ['Thousands', 'of', 'demonstrators', 'have', '...   \n",
       "1         Sentence: 10  ['Iranian', 'officials', 'say', 'they', 'expec...   \n",
       "2        Sentence: 100  ['Helicopter', 'gunships', 'Saturday', 'pounde...   \n",
       "3       Sentence: 1000  ['They', 'left', 'after', 'a', 'tense', 'hour-...   \n",
       "4      Sentence: 10000  ['U.N.', 'relief', 'coordinator', 'Jan', 'Egel...   \n",
       "...                ...                                                ...   \n",
       "47954   Sentence: 9995  ['Opposition', 'leader', 'Mir', 'Hossein', 'Mo...   \n",
       "47955   Sentence: 9996  ['On', 'Thursday', ',', 'Iranian', 'state', 'm...   \n",
       "47956   Sentence: 9997  ['Following', 'Iran', \"'s\", 'disputed', 'June'...   \n",
       "47957   Sentence: 9998  ['Since', 'then', ',', 'authorities', 'have', ...   \n",
       "47958   Sentence: 9999  ['The', 'United', 'Nations', 'is', 'praising',...   \n",
       "\n",
       "                                                     POS  \\\n",
       "0      ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n",
       "1      ['JJ', 'NNS', 'VBP', 'PRP', 'VBP', 'TO', 'VB',...   \n",
       "2      ['NN', 'NNS', 'NNP', 'VBD', 'JJ', 'NNS', 'IN',...   \n",
       "3      ['PRP', 'VBD', 'IN', 'DT', 'NN', 'JJ', 'NN', '...   \n",
       "4      ['NNP', 'NN', 'NN', 'NNP', 'NNP', 'VBD', 'NNP'...   \n",
       "...                                                  ...   \n",
       "47954  ['NNP', 'NN', 'NNP', 'NNP', 'NNP', 'VBZ', 'VBN...   \n",
       "47955  ['IN', 'NNP', ',', 'JJ', 'NN', 'NNS', 'VBN', '...   \n",
       "47956  ['VBG', 'NNP', 'POS', 'JJ', 'NNP', 'CD', 'NNS'...   \n",
       "47957  ['IN', 'RB', ',', 'NNS', 'VBP', 'VBN', 'JJ', '...   \n",
       "47958  ['DT', 'NNP', 'NNP', 'VBZ', 'VBG', 'DT', 'NN',...   \n",
       "\n",
       "                                                     Tag  \n",
       "0      ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n",
       "1      ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...  \n",
       "2      ['O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', '...  \n",
       "3      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "4      ['B-geo', 'O', 'O', 'B-per', 'I-per', 'O', 'B-...  \n",
       "...                                                  ...  \n",
       "47954  ['O', 'O', 'O', 'B-per', 'I-per', 'O', 'O', 'O...  \n",
       "47955  ['O', 'B-tim', 'O', 'B-gpe', 'O', 'O', 'O', 'O...  \n",
       "47956  ['O', 'B-geo', 'O', 'O', 'B-tim', 'I-tim', 'O'...  \n",
       "47957  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "47958  ['O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O...  \n",
       "\n",
       "[47959 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa48c79",
   "metadata": {
    "papermill": {
     "duration": 0.013014,
     "end_time": "2024-11-11T22:50:02.540634",
     "exception": false,
     "start_time": "2024-11-11T22:50:02.527620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA\n",
    "Investigate how many Tags are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7cef76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:02.566734Z",
     "iopub.status.busy": "2024-11-11T22:50:02.566318Z",
     "iopub.status.idle": "2024-11-11T22:50:26.823486Z",
     "shell.execute_reply": "2024-11-11T22:50:26.822481Z"
    },
    "papermill": {
     "duration": 24.273285,
     "end_time": "2024-11-11T22:50:26.826062",
     "exception": false,
     "start_time": "2024-11-11T22:50:02.552777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'O'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast \n",
    "\n",
    "# Current data has list form read in literal. Change this to list form\n",
    "for i, row in df.iterrows():\n",
    "    df.loc[i, 'Word'] = ast.literal_eval(df.loc[i, 'Word'])\n",
    "    df.loc[i, 'Tag'] = ast.literal_eval(df.loc[i, 'Tag'])\n",
    "\n",
    "unique_tags = set()\n",
    "\n",
    "def add_unique_tags(row):\n",
    "    taglist = row['Tag']\n",
    "    for tag in taglist:\n",
    "        # Add the tag only if not in the unique_tags set\n",
    "        if tag not in unique_tags:\n",
    "            unique_tags.add(tag)\n",
    "\n",
    "df.apply(add_unique_tags, axis=1)\n",
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef71c652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:26.852593Z",
     "iopub.status.busy": "2024-11-11T22:50:26.852176Z",
     "iopub.status.idle": "2024-11-11T22:50:26.857722Z",
     "shell.execute_reply": "2024-11-11T22:50:26.856643Z"
    },
    "papermill": {
     "duration": 0.021625,
     "end_time": "2024-11-11T22:50:26.860044",
     "exception": false,
     "start_time": "2024-11-11T22:50:26.838419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's hardcode the tags to reorder\n",
    "tags = ['O', 'B-art', 'I-art', 'B-eve', 'I-eve', 'B-geo', 'I-geo', 'B-gpe', 'I-gpe', \n",
    "        'B-nat', 'I-nat', 'B-org', 'I-org', 'B-per', 'I-per', 'B-tim', 'I-tim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b8a820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:26.886212Z",
     "iopub.status.busy": "2024-11-11T22:50:26.885840Z",
     "iopub.status.idle": "2024-11-11T22:50:28.210189Z",
     "shell.execute_reply": "2024-11-11T22:50:28.209115Z"
    },
    "papermill": {
     "duration": 1.340568,
     "end_time": "2024-11-11T22:50:28.212868",
     "exception": false,
     "start_time": "2024-11-11T22:50:26.872300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Word'], df['Tag'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c95b417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:28.239303Z",
     "iopub.status.busy": "2024-11-11T22:50:28.238758Z",
     "iopub.status.idle": "2024-11-11T22:50:28.248607Z",
     "shell.execute_reply": "2024-11-11T22:50:28.247614Z"
    },
    "papermill": {
     "duration": 0.025424,
     "end_time": "2024-11-11T22:50:28.250929",
     "exception": false,
     "start_time": "2024-11-11T22:50:28.225505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thousands',\n",
       " 'of',\n",
       " 'demonstrators',\n",
       " 'have',\n",
       " 'marched',\n",
       " 'through',\n",
       " 'London',\n",
       " 'to',\n",
       " 'protest',\n",
       " 'the',\n",
       " 'war',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'and',\n",
       " 'demand',\n",
       " 'the',\n",
       " 'withdrawal',\n",
       " 'of',\n",
       " 'British',\n",
       " 'troops',\n",
       " 'from',\n",
       " 'that',\n",
       " 'country',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e6f62",
   "metadata": {
    "papermill": {
     "duration": 0.0117,
     "end_time": "2024-11-11T22:50:28.274891",
     "exception": false,
     "start_time": "2024-11-11T22:50:28.263191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Vocabulary\n",
    "(Note: 'O' tagged tokens will be excluded from the vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "275a0725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:28.301019Z",
     "iopub.status.busy": "2024-11-11T22:50:28.300612Z",
     "iopub.status.idle": "2024-11-11T22:50:28.307375Z",
     "shell.execute_reply": "2024-11-11T22:50:28.306277Z"
    },
    "papermill": {
     "duration": 0.022384,
     "end_time": "2024-11-11T22:50:28.309650",
     "exception": false,
     "start_time": "2024-11-11T22:50:28.287266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_vocab(x_data, y_labels):\n",
    "    '''\n",
    "    Args:\n",
    "        :x_data: (train_data_length, sentence_length)\n",
    "        :y)data: (train_data_length, 1)\n",
    "    '''\n",
    "    vocab = set()\n",
    "    \n",
    "    # Loop through each sentence\n",
    "    for sentence, tags in zip(x_data, y_labels):\n",
    "        # Loop through each token\n",
    "        for token, tag in zip(sentence, tags):\n",
    "            if tag != 'O':\n",
    "                vocab.add(token)\n",
    "                \n",
    "    vocab = list(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac4666f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:28.335567Z",
     "iopub.status.busy": "2024-11-11T22:50:28.334748Z",
     "iopub.status.idle": "2024-11-11T22:50:28.582526Z",
     "shell.execute_reply": "2024-11-11T22:50:28.581519Z"
    },
    "papermill": {
     "duration": 0.263377,
     "end_time": "2024-11-11T22:50:28.585105",
     "exception": false,
     "start_time": "2024-11-11T22:50:28.321728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_train = make_vocab(X_train, y_train)\n",
    "vocab_test = make_vocab(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb4805b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:28.611998Z",
     "iopub.status.busy": "2024-11-11T22:50:28.611562Z",
     "iopub.status.idle": "2024-11-11T22:50:28.617333Z",
     "shell.execute_reply": "2024-11-11T22:50:28.616282Z"
    },
    "papermill": {
     "duration": 0.022429,
     "end_time": "2024-11-11T22:50:28.620173",
     "exception": false,
     "start_time": "2024-11-11T22:50:28.597744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary of train dataset: 12061\n",
      "Length of vocabulary of test dataset:  5686\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of vocabulary of train dataset: {len(vocab_train)}\")\n",
    "print(f\"Length of vocabulary of test dataset:  {len(vocab_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d9000f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:28.648612Z",
     "iopub.status.busy": "2024-11-11T22:50:28.648172Z",
     "iopub.status.idle": "2024-11-11T22:50:29.865676Z",
     "shell.execute_reply": "2024-11-11T22:50:29.864397Z"
    },
    "papermill": {
     "duration": 1.235474,
     "end_time": "2024-11-11T22:50:29.868417",
     "exception": false,
     "start_time": "2024-11-11T22:50:28.632943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1498 Tokens from vocab_test are not in vocab_train\n"
     ]
    }
   ],
   "source": [
    "# Checking how many tokens from test vocab is NOT in train vocab\n",
    "count = 0\n",
    "for i in range(len(vocab_test)):\n",
    "    if vocab_test[i] not in vocab_train:\n",
    "        count += 1\n",
    "\n",
    "print(f\"{count} Tokens from vocab_test are not in vocab_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d22330",
   "metadata": {
    "papermill": {
     "duration": 0.011755,
     "end_time": "2024-11-11T22:50:29.893057",
     "exception": false,
     "start_time": "2024-11-11T22:50:29.881302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encoding\n",
    "Encoding each token to integers\n",
    "* Special Tokens x->y mapping:\n",
    "    * '\\<PAD\\>' -> '\\<PAD\\>'\n",
    "    * '\\<UNK\\>' -> 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e69a70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:29.918730Z",
     "iopub.status.busy": "2024-11-11T22:50:29.918309Z",
     "iopub.status.idle": "2024-11-11T22:50:29.925074Z",
     "shell.execute_reply": "2024-11-11T22:50:29.924064Z"
    },
    "papermill": {
     "duration": 0.022285,
     "end_time": "2024-11-11T22:50:29.927340",
     "exception": false,
     "start_time": "2024-11-11T22:50:29.905055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word2idx(special_tokens, vocab):\n",
    "    num_spec_tokens = len(special_tokens)\n",
    "    # Word2idx\n",
    "    word_to_idx = {spec: idx for idx, spec in enumerate(special_tokens)} # Adding special tokens\n",
    "    word_to_idx.update({token: (idx + num_spec_tokens) for idx, token in enumerate(vocab)}) # Adding non-special vocab tokens\n",
    "    # idx2Word\n",
    "    idx_to_word = {idx: token for token, idx in word_to_idx.items()} # Key-value swapping\n",
    "    \n",
    "    return word_to_idx, idx_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e70570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:29.954002Z",
     "iopub.status.busy": "2024-11-11T22:50:29.953584Z",
     "iopub.status.idle": "2024-11-11T22:50:29.968721Z",
     "shell.execute_reply": "2024-11-11T22:50:29.967677Z"
    },
    "papermill": {
     "duration": 0.031511,
     "end_time": "2024-11-11T22:50:29.971127",
     "exception": false,
     "start_time": "2024-11-11T22:50:29.939616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token2idx, idx2token = word2idx(['<PAD>', '<UNK>'], vocab_train)\n",
    "tag2idx, idx2tag = word2idx(['<PAD>'], tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b2643ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:29.998271Z",
     "iopub.status.busy": "2024-11-11T22:50:29.997882Z",
     "iopub.status.idle": "2024-11-11T22:50:30.005472Z",
     "shell.execute_reply": "2024-11-11T22:50:30.004387Z"
    },
    "papermill": {
     "duration": 0.024002,
     "end_time": "2024-11-11T22:50:30.007855",
     "exception": false,
     "start_time": "2024-11-11T22:50:29.983853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " 'O': 1,\n",
       " 'B-art': 2,\n",
       " 'I-art': 3,\n",
       " 'B-eve': 4,\n",
       " 'I-eve': 5,\n",
       " 'B-geo': 6,\n",
       " 'I-geo': 7,\n",
       " 'B-gpe': 8,\n",
       " 'I-gpe': 9,\n",
       " 'B-nat': 10,\n",
       " 'I-nat': 11,\n",
       " 'B-org': 12,\n",
       " 'I-org': 13,\n",
       " 'B-per': 14,\n",
       " 'I-per': 15,\n",
       " 'B-tim': 16,\n",
       " 'I-tim': 17}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b33627ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:30.035092Z",
     "iopub.status.busy": "2024-11-11T22:50:30.034627Z",
     "iopub.status.idle": "2024-11-11T22:50:30.041965Z",
     "shell.execute_reply": "2024-11-11T22:50:30.040881Z"
    },
    "papermill": {
     "duration": 0.023583,
     "end_time": "2024-11-11T22:50:30.044324",
     "exception": false,
     "start_time": "2024-11-11T22:50:30.020741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encoding Tokenized data\n",
    "def encode_tokens(tokenized_data, token2idx, unknown_token='<UNK>'):\n",
    "    '''\n",
    "    Args:\n",
    "        :tokenized_data: (dataset_length, sequence_length)\n",
    "        :token2idx: {token : idx}\n",
    "        :unknown_token: The token that the unknown tokens(not in vocab e.g. token2idx) will be mapped to \n",
    "    Returns:\n",
    "        :encoded_data: listof(listof(int))\n",
    "    '''\n",
    "    encoded_data = []\n",
    "    \n",
    "    for sent in tokenized_data:\n",
    "        encoded_sent = []\n",
    "        for token in sent:\n",
    "            try:\n",
    "                encoded_sent.append(token2idx[token])\n",
    "            except KeyError: # If not found, it means unkown token\n",
    "                encoded_sent.append(token2idx[unknown_token])\n",
    "        # Adding encoded sentence to the final output\n",
    "        encoded_data.append(encoded_sent)\n",
    "    \n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eea5aff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:30.071891Z",
     "iopub.status.busy": "2024-11-11T22:50:30.071430Z",
     "iopub.status.idle": "2024-11-11T22:50:31.049947Z",
     "shell.execute_reply": "2024-11-11T22:50:31.048778Z"
    },
    "papermill": {
     "duration": 0.995353,
     "end_time": "2024-11-11T22:50:31.052762",
     "exception": false,
     "start_time": "2024-11-11T22:50:30.057409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X dataset\n",
    "enc_X_train = encode_tokens(X_train, token2idx, '<UNK>')\n",
    "enc_X_test = encode_tokens(X_test, token2idx, '<UNK>')\n",
    "# y dataset\n",
    "enc_y_train = encode_tokens(y_train, tag2idx, 'O')\n",
    "enc_y_test = encode_tokens(y_test, tag2idx, 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e95035a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:31.080924Z",
     "iopub.status.busy": "2024-11-11T22:50:31.079887Z",
     "iopub.status.idle": "2024-11-11T22:50:31.084781Z",
     "shell.execute_reply": "2024-11-11T22:50:31.083752Z"
    },
    "papermill": {
     "duration": 0.021113,
     "end_time": "2024-11-11T22:50:31.087054",
     "exception": false,
     "start_time": "2024-11-11T22:50:31.065941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#enc_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02bc20b",
   "metadata": {
    "papermill": {
     "duration": 0.012314,
     "end_time": "2024-11-11T22:50:31.112203",
     "exception": false,
     "start_time": "2024-11-11T22:50:31.099889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Determine Context Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df8fae2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:31.139064Z",
     "iopub.status.busy": "2024-11-11T22:50:31.138645Z",
     "iopub.status.idle": "2024-11-11T22:50:31.156668Z",
     "shell.execute_reply": "2024-11-11T22:50:31.155209Z"
    },
    "papermill": {
     "duration": 0.034525,
     "end_time": "2024-11-11T22:50:31.159216",
     "exception": false,
     "start_time": "2024-11-11T22:50:31.124691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 문장 길이가 40 이하 데이터 비율: 98.40%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def set_sent_pad(encode_x, context_length, report=False):\n",
    "    if report:\n",
    "        print(f'훈련 데이터셋 최대 길이: {max(len(exam) for exam in encode_x)}')\n",
    "        print(f'훈련 데이터셋 평균 길이: {sum(map(len, encode_x)) / len(encode_x):.2f}')\n",
    "\n",
    "        plt.hist([len(exam) for exam in encode_x], bins=50)\n",
    "        plt.xlabel('length of samples')\n",
    "        plt.ylabel('number of samples')\n",
    "        plt.show()\n",
    "\n",
    "    def below_th_len(encode_x, context_length):\n",
    "        cnt = 0\n",
    "        for sent in encode_x:\n",
    "            if(len(sent) <= context_length):\n",
    "                cnt +=1\n",
    "        \n",
    "        print(f'데이터셋 문장 길이가 {context_length} 이하 데이터 비율: '+\n",
    "              f'{cnt / len(encode_x)*100:.2f}%')\n",
    "        \n",
    "    below_th_len(encode_x, context_length)\n",
    "    \n",
    "set_sent_pad(enc_X_train, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adec716",
   "metadata": {
    "papermill": {
     "duration": 0.012654,
     "end_time": "2024-11-11T22:50:31.184667",
     "exception": false,
     "start_time": "2024-11-11T22:50:31.172013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "737e58d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:31.211597Z",
     "iopub.status.busy": "2024-11-11T22:50:31.211202Z",
     "iopub.status.idle": "2024-11-11T22:50:31.217742Z",
     "shell.execute_reply": "2024-11-11T22:50:31.216696Z"
    },
    "papermill": {
     "duration": 0.022846,
     "end_time": "2024-11-11T22:50:31.220139",
     "exception": false,
     "start_time": "2024-11-11T22:50:31.197293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_seq(dataset, context_length):\n",
    "    padded = np.zeros((len(dataset), context_length), dtype=int)\n",
    "    for idx, sent in enumerate(dataset):\n",
    "        if len(sent) != 0:\n",
    "            padded[idx, :len(sent)] = np.array(sent)[:context_length]\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff2b53b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:31.247697Z",
     "iopub.status.busy": "2024-11-11T22:50:31.246962Z",
     "iopub.status.idle": "2024-11-11T22:50:31.715536Z",
     "shell.execute_reply": "2024-11-11T22:50:31.714418Z"
    },
    "papermill": {
     "duration": 0.485423,
     "end_time": "2024-11-11T22:50:31.718228",
     "exception": false,
     "start_time": "2024-11-11T22:50:31.232805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = 40\n",
    "# X datasets\n",
    "pad_X_train = pad_seq(enc_X_train, CONTEXT_LENGTH)\n",
    "pad_X_test = pad_seq(enc_X_test, CONTEXT_LENGTH)\n",
    "# y datasets\n",
    "pad_y_train = pad_seq(enc_y_train, CONTEXT_LENGTH)\n",
    "pad_y_test = pad_seq(enc_y_test, CONTEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52d8ad73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:31.746288Z",
     "iopub.status.busy": "2024-11-11T22:50:31.745330Z",
     "iopub.status.idle": "2024-11-11T22:50:31.750949Z",
     "shell.execute_reply": "2024-11-11T22:50:31.749877Z"
    },
    "papermill": {
     "duration": 0.022409,
     "end_time": "2024-11-11T22:50:31.753506",
     "exception": false,
     "start_time": "2024-11-11T22:50:31.731097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38367, 40)\n",
      "(38367, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{pad_X_train.shape}\")\n",
    "print(f\"{pad_y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b936ff1b",
   "metadata": {
    "papermill": {
     "duration": 0.012424,
     "end_time": "2024-11-11T22:50:31.778838",
     "exception": false,
     "start_time": "2024-11-11T22:50:31.766414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cbed2ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:31.805901Z",
     "iopub.status.busy": "2024-11-11T22:50:31.805480Z",
     "iopub.status.idle": "2024-11-11T22:50:35.920333Z",
     "shell.execute_reply": "2024-11-11T22:50:35.918879Z"
    },
    "papermill": {
     "duration": 4.131758,
     "end_time": "2024-11-11T22:50:35.923107",
     "exception": false,
     "start_time": "2024-11-11T22:50:31.791349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def set_dataloader(x_data, y_label, bs, training=False):\n",
    "    tensor_x = torch.tensor(x_data, dtype=torch.int64)\n",
    "    tensor_y = torch.tensor(y_label, dtype=torch.int64)\n",
    "    \n",
    "    dataset = TensorDataset(tensor_x, tensor_y)\n",
    "    \n",
    "    shuffle=False\n",
    "    if training:\n",
    "        shuffle=True\n",
    "    \n",
    "    dataloader = DataLoader(dataset, shuffle=shuffle, batch_size=bs)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42d38ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:35.953092Z",
     "iopub.status.busy": "2024-11-11T22:50:35.952246Z",
     "iopub.status.idle": "2024-11-11T22:50:36.004337Z",
     "shell.execute_reply": "2024-11-11T22:50:36.003164Z"
    },
    "papermill": {
     "duration": 0.071985,
     "end_time": "2024-11-11T22:50:36.007683",
     "exception": false,
     "start_time": "2024-11-11T22:50:35.935698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 48\n",
    "\n",
    "train_dataloader = set_dataloader(pad_X_train, pad_y_train, bs=BATCH_SIZE, training=True)\n",
    "test_dataloader = set_dataloader(pad_X_test, pad_y_test, bs=BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9a8c6",
   "metadata": {
    "papermill": {
     "duration": 0.014714,
     "end_time": "2024-11-11T22:50:36.040598",
     "exception": false,
     "start_time": "2024-11-11T22:50:36.025884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9f1cba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:36.083734Z",
     "iopub.status.busy": "2024-11-11T22:50:36.083216Z",
     "iopub.status.idle": "2024-11-11T22:50:36.094254Z",
     "shell.execute_reply": "2024-11-11T22:50:36.093426Z"
    },
    "papermill": {
     "duration": 0.035942,
     "end_time": "2024-11-11T22:50:36.096768",
     "exception": false,
     "start_time": "2024-11-11T22:50:36.060826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class RNN_Tagger(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, \n",
    "                 num_tags=18, num_layers=2, embed_matrix=None):\n",
    "        super().__init__()\n",
    "        # Embedding Layer\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        # If pretrained-embedding is used\n",
    "        if embed_matrix is not None:\n",
    "            # Transferring weights\n",
    "            self.embed.weight = nn.Parameter(\n",
    "                torch.tensor(embed_matrix, dtype=torch.float32)\n",
    "            )\n",
    "            self.embed.weight.requires_grad = True\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size=embed_dim,\n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=num_layers,\n",
    "                          bidirectional=True,\n",
    "                          batch_first=True)\n",
    "        # Classifier Layer \n",
    "        # Since bidirectional, input size is hidden_dim*2\n",
    "        self.classifier = nn.Linear(hidden_dim*2, num_tags)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Input:\n",
    "            :x: (batch_size, context_length) \n",
    "        '''\n",
    "        emb_x = self.embed(x) # :emb_x: (batch_size, context_length, embed_dim)\n",
    "        output, hidden = self.rnn(emb_x) # :output: (batch_size, context_length, hidden_dim*2)\n",
    "        logits = self.classifier(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "899ea466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:36.135642Z",
     "iopub.status.busy": "2024-11-11T22:50:36.134345Z",
     "iopub.status.idle": "2024-11-11T22:50:36.140192Z",
     "shell.execute_reply": "2024-11-11T22:50:36.139236Z"
    },
    "papermill": {
     "duration": 0.028116,
     "end_time": "2024-11-11T22:50:36.143066",
     "exception": false,
     "start_time": "2024-11-11T22:50:36.114950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters & Model variables\n",
    "VOCAB_SIZE = len(vocab_train)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 500\n",
    "NUM_TAGS = len(tag2idx)\n",
    "NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24df04fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:36.182223Z",
     "iopub.status.busy": "2024-11-11T22:50:36.181371Z",
     "iopub.status.idle": "2024-11-11T22:50:36.562423Z",
     "shell.execute_reply": "2024-11-11T22:50:36.561348Z"
    },
    "papermill": {
     "duration": 0.403747,
     "end_time": "2024-11-11T22:50:36.565401",
     "exception": false,
     "start_time": "2024-11-11T22:50:36.161654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "RNN_NERtagger = RNN_Tagger(vocab_size=VOCAB_SIZE, embed_dim=EMBEDDING_DIM,\n",
    "                           hidden_dim=HIDDEN_DIM, num_tags=NUM_TAGS, num_layers=NUM_LAYERS)\n",
    "RNN_NERtagger = RNN_NERtagger.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d84f14",
   "metadata": {
    "papermill": {
     "duration": 0.012483,
     "end_time": "2024-11-11T22:50:36.594247",
     "exception": false,
     "start_time": "2024-11-11T22:50:36.581764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "535c9a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:36.622871Z",
     "iopub.status.busy": "2024-11-11T22:50:36.621864Z",
     "iopub.status.idle": "2024-11-11T22:50:38.006480Z",
     "shell.execute_reply": "2024-11-11T22:50:38.005507Z"
    },
    "papermill": {
     "duration": 1.402112,
     "end_time": "2024-11-11T22:50:38.009466",
     "exception": false,
     "start_time": "2024-11-11T22:50:36.607354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Don't count '<PAD>' tokens when calculating loss\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "# Opimizer\n",
    "optimizer = optim.Adam(RNN_NERtagger.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad63d3",
   "metadata": {
    "papermill": {
     "duration": 0.012578,
     "end_time": "2024-11-11T22:50:38.034879",
     "exception": false,
     "start_time": "2024-11-11T22:50:38.022301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "482cdd65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:38.062048Z",
     "iopub.status.busy": "2024-11-11T22:50:38.061426Z",
     "iopub.status.idle": "2024-11-11T22:50:38.072593Z",
     "shell.execute_reply": "2024-11-11T22:50:38.071418Z"
    },
    "papermill": {
     "duration": 0.027416,
     "end_time": "2024-11-11T22:50:38.074957",
     "exception": false,
     "start_time": "2024-11-11T22:50:38.047541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, \n",
    "          loss_fn, optimizer):\n",
    "    \n",
    "    model.train()\n",
    "    total, correct = 0, 0\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    \n",
    "    for X, y in tqdm(dataloader):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        pred_logits = model(X)\n",
    "        # Reshape pred and traget before feeding into loss_fn\n",
    "        batch_size, context_length, num_tags = pred_logits.size()\n",
    "        pred_logits = pred_logits.reshape(-1, num_tags) # -> (bs*context_length, num_tags)\n",
    "        y = y.reshape(-1) # (batch_size, context_length) -> (batch_size*context_length)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        loss = loss_fn(pred_logits, y)\n",
    "        # optimizer zero_grad\n",
    "        optimizer.zero_grad()\n",
    "        # loss backward\n",
    "        loss.backward()\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculating Accuracy\n",
    "        y_pred = torch.argmax(pred_logits, axis=1)\n",
    "        # Masking to not count <PAD> as correct\n",
    "        IGNORE_IDX = 0 # <PAD> = 0\n",
    "        mask = (y != IGNORE_IDX)\n",
    "        total += mask.sum().item()\n",
    "        correct += y_pred.eq(y.view_as(y_pred)).masked_select(mask).sum().item()\n",
    "    \n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc = 100 * (correct / total)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84b03192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:38.102026Z",
     "iopub.status.busy": "2024-11-11T22:50:38.101591Z",
     "iopub.status.idle": "2024-11-11T22:50:38.111760Z",
     "shell.execute_reply": "2024-11-11T22:50:38.110773Z"
    },
    "papermill": {
     "duration": 0.026476,
     "end_time": "2024-11-11T22:50:38.114214",
     "exception": false,
     "start_time": "2024-11-11T22:50:38.087738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    test_loss, test_acc = 0.0, 0.0\n",
    "    \n",
    "    for X, y in tqdm(dataloader):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        pred_logits = model(X)\n",
    "        \n",
    "        # Reshape pred and traget before feeding into loss_fn\n",
    "        batch_size, context_length, num_tags = pred_logits.size()\n",
    "        pred_logits = pred_logits.reshape(-1, num_tags) # -> (bs*context_length, num_tags)\n",
    "        y = y.reshape(-1) # (batch_size, context_length) -> (batch_size*context_length)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        loss = loss_fn(pred_logits, y)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        #Calculating Accuracy\n",
    "        y_pred = torch.argmax(pred_logits, axis=1)\n",
    "        # Masking to not count <PAD> as correct\n",
    "        IGNORE_IDX = 0 # <PAD> = 0\n",
    "        mask = (y != IGNORE_IDX)\n",
    "        total += mask.sum().item()\n",
    "        correct += y_pred.eq(y.view_as(y_pred)).masked_select(mask).sum().item()\n",
    "    \n",
    "    test_loss /= len(dataloader)\n",
    "    test_acc = 100 * (correct / total)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04954e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:38.141866Z",
     "iopub.status.busy": "2024-11-11T22:50:38.141418Z",
     "iopub.status.idle": "2024-11-11T22:50:38.150866Z",
     "shell.execute_reply": "2024-11-11T22:50:38.149705Z"
    },
    "papermill": {
     "duration": 0.026042,
     "end_time": "2024-11-11T22:50:38.153293",
     "exception": false,
     "start_time": "2024-11-11T22:50:38.127251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "def model_train(model, train_dataloader, test_dataloader,\n",
    "                loss_fn, optimizer, num_epochs):\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start = time.time()\n",
    "        train_loss, train_acc = train(model, train_dataloader, loss_fn, optimizer)\n",
    "        test_loss, test_acc = evaluate(model, test_dataloader, loss_fn)\n",
    "        \n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        end = time.time()\n",
    "        print(f\"------------ epoch {epoch} ------------\")\n",
    "        print(f\"Train loss: {train_loss:.4f} | Train acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val loss: {val_loss:.4f} | Val acc: {val_acc:2f}%\")\n",
    "        print(f\"Time taken: {(end - start) / 60:.0f}min {(end - start) % 60:.0f}s\")\n",
    "        \n",
    "    # Finalize the best model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52484090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T22:50:38.181610Z",
     "iopub.status.busy": "2024-11-11T22:50:38.180620Z",
     "iopub.status.idle": "2024-11-11T22:50:38.185513Z",
     "shell.execute_reply": "2024-11-11T22:50:38.184484Z"
    },
    "papermill": {
     "duration": 0.021855,
     "end_time": "2024-11-11T22:50:38.187969",
     "exception": false,
     "start_time": "2024-11-11T22:50:38.166114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled = False\n",
    "\n",
    "# RNN_tagger_model = model_train(RNN_NERtagger, \n",
    "#                                train_dataloader, \n",
    "#                                test_dataloader, \n",
    "#                                loss_fn, \n",
    "#                                optimizer, \n",
    "#                                10)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 902647,
     "sourceId": 1530946,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.834842,
   "end_time": "2024-11-11T22:50:40.674149",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-11T22:49:57.839307",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
